{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"原理：其实我们就是通过encoder和decoder去将一张图片重新编码和解码，对于model见过的图片，经历过整个流程，所以model知道如何还原这张图片，所以经由模型生成的图片和原来的图片是比较相近的；而对于model未曾见过的图片，他不知道该如何复原这张图片，所以经由模型生成的图片和原来的图片差别会比较大\n\n\n在test的过程中，我们对原图与model生成的图取平方差，理想的结果是train过的图片对的方差较小，没有train过的图片对方差较大，根据这点不同可以判断做异常检测","metadata":{}},{"cell_type":"code","source":"!git clone https://github.com/wkentaro/gdown\n!cd gdown\n!pip install gdown","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-25T02:45:13.615633Z","iopub.execute_input":"2021-05-25T02:45:13.616002Z","iopub.status.idle":"2021-05-25T02:45:22.772724Z","shell.execute_reply.started":"2021-05-25T02:45:13.615967Z","shell.execute_reply":"2021-05-25T02:45:22.771375Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"fatal: destination path 'gdown' already exists and is not an empty directory.\nRequirement already satisfied: gdown in /opt/conda/lib/python3.7/site-packages (3.13.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.0.12)\nRequirement already satisfied: requests[socks]>=2.12.0 in /opt/conda/lib/python3.7/site-packages (from gdown) (2.25.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.56.2)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (1.26.3)\nRequirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (2.10)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (2020.12.5)\nRequirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (3.0.4)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]>=2.12.0->gdown) (1.7.1)\n","output_type":"stream"}]},{"cell_type":"code","source":"!gdown --id '1_zT3JOpvXFGr7mkxs3XJDeGxTn_8pItq' --output train.npy \n!gdown --id '11Y_6JDjlhIY-M5-jW1rLRshDMqeKi9Kr' --output test.npy \n\nimport numpy as np\n\ntrain = np.load('train.npy', allow_pickle=True)\ntest = np.load('test.npy', allow_pickle=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T02:45:32.242182Z","iopub.execute_input":"2021-05-25T02:45:32.242540Z","iopub.status.idle":"2021-05-25T02:45:46.576370Z","shell.execute_reply.started":"2021-05-25T02:45:32.242507Z","shell.execute_reply":"2021-05-25T02:45:46.575276Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading...\nFrom: https://drive.google.com/uc?id=1_zT3JOpvXFGr7mkxs3XJDeGxTn_8pItq\nTo: /kaggle/working/train.npy\n983MB [00:06, 142MB/s]  \nDownloading...\nFrom: https://drive.google.com/uc?id=11Y_6JDjlhIY-M5-jW1rLRshDMqeKi9Kr\nTo: /kaggle/working/test.npy\n246MB [00:01, 199MB/s]  \n","output_type":"stream"}]},{"cell_type":"code","source":"from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\nimport torch\ndata = torch.tensor(train, dtype=torch.float)\ntrain_dataset = TensorDataset(data)\ntrain_sampler = RandomSampler(train_dataset)\ntrain_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=2)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T02:46:08.594170Z","iopub.execute_input":"2021-05-25T02:46:08.594558Z","iopub.status.idle":"2021-05-25T02:46:08.976943Z","shell.execute_reply.started":"2021-05-25T02:46:08.594524Z","shell.execute_reply":"2021-05-25T02:46:08.975619Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"task = 'ae'","metadata":{"execution":{"iopub.status.busy":"2021-05-25T02:46:10.707655Z","iopub.execute_input":"2021-05-25T02:46:10.708046Z","iopub.status.idle":"2021-05-25T02:46:10.713037Z","shell.execute_reply.started":"2021-05-25T02:46:10.708014Z","shell.execute_reply":"2021-05-25T02:46:10.711819Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport torch.nn.functional as F\n\nclass fcn_autoencoder(nn.Module):\n    def __init__(self):\n        super(fcn_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Linear(32*32*3, 128),\n            nn.ReLU(True),\n            nn.Linear(128, 64),\n            nn.ReLU(True),\n            nn.Linear(64, 12),\n            nn.ReLU(True),\n            nn.Linear(12, 3),\n        )\n        self.decoder = nn.Sequential(\n            nn.Linear(3, 12),\n            nn.ReLU(True),\n            nn.Linear(12, 64),\n            nn.ReLU(True),\n            nn.Linear(64, 128),\n            nn.ReLU(True),\n            nn.Linear(128, 32*32*3),\n            nn.Tanh()\n        )\n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-25T02:46:12.555327Z","iopub.execute_input":"2021-05-25T02:46:12.555714Z","iopub.status.idle":"2021-05-25T02:46:12.568150Z","shell.execute_reply.started":"2021-05-25T02:46:12.555683Z","shell.execute_reply":"2021-05-25T02:46:12.564612Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class conv_autoencoder(nn.Module):\n    def __init__(self):\n        super(conv_autoencoder, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 12, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(12, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.Conv2d(24, 48, 4, stride=2, padding=1),\n            nn.ReLU(),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(48, 24, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(24, 12, 4, stride=2, padding=1),\n            nn.ReLU(),\n            nn.ConvTranspose2d(12, 3, 4, stride=2, padding=1),\n            nn.Tanh(),\n        )\n    \n    def forward(self, x):\n        x = self.encoder(x)\n        x = self.decoder(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-25T02:46:14.234605Z","iopub.execute_input":"2021-05-25T02:46:14.234993Z","iopub.status.idle":"2021-05-25T02:46:14.244405Z","shell.execute_reply.started":"2021-05-25T02:46:14.234959Z","shell.execute_reply":"2021-05-25T02:46:14.243220Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self):\n        super(VAE, self).__init__()\n        self.fc1 = nn.Linear(32*32*3,  400)\n        self.fc21 = nn.Linear(400, 20)\n        self.fc22 = nn.Linear(400, 20)\n        self.fc3 = nn.Linear(20, 400)\n        self.fc4 = nn.Linear(400, 32*32*3)\n        \n    def encode(self, x):\n        h1 = F.relu(self.fc1(x))\n        return self.fc21(h1), self.fc22(h1)\n    \n    def reparametrize(self, mu, logvar):\n        std = logvar.mul(0.5).exp_()\n        if torch.cuda.is_available():\n            eps = torch.cuda.FloatTensor(std.size()).normal_()\n        else:\n            eps = torch.FloatTensor(std.size()).normal_()\n        eps = Variable(eps)\n        return eps.mul(std).add_(mu)\n    \n    def decode(self, z):\n        h3 = F.relu(self.fc3(z))\n        return F.sigmoid(self.fc4(h3))\n    \n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparametrize(mu, logvar)\n        return self.decode(z), mu, logvar\n    \ndef loss_vae(recon_x, x, mu, logvar, criterion):\n    mse = criterion(recon_x, x)\n    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n    KLD = torch.sum(KLD_element).mul_(-0.5)\n    return mse+KLD","metadata":{"execution":{"iopub.status.busy":"2021-05-25T02:46:15.154287Z","iopub.execute_input":"2021-05-25T02:46:15.154641Z","iopub.status.idle":"2021-05-25T02:46:15.171012Z","shell.execute_reply.started":"2021-05-25T02:46:15.154610Z","shell.execute_reply":"2021-05-25T02:46:15.170030Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam, AdamW\nfrom torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n\nif task == 'ae':\n    num_epochs = 1000\n    batch_size = 128\n    learning_rate = 1e-3\n    \n    model_type = 'cnn'\n    x = train\n    if model_type == 'fcn' or model_type == 'vae':\n        x =x.reshape(len(x), -1)\n        \n    data = torch.tensor(x, dtype=torch.float)\n    train_sampler = RandomSampler(train_dataset)\n    train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n    \n    model_classes = {'fcn':fcn_autoencoder(), 'cnn':conv_autoencoder(), 'vae':VAE()}\n    model = model_classes[model_type].cuda()\n    criterion = nn.MSELoss()\n    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n    \n    best_loss = 1000\n    model.train()\n    \n    for epoch in range(num_epochs):\n        for data in train_dataloader:\n            if model_type == 'cnn':\n                img = data[0].transpose(3, 1).cuda()\n            else:\n                img = data[0].cuda()\n            \n            output = model(img)\n            if model_type == 'vae':\n                loss = loss_vae(output[0], img, output[1], output[2], criterion)\n            else:\n                loss = criterion(output, img)\n            \n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n        if loss.item() < best_loss:\n            best_loss = loss.item()\n            torch.save(model, 'best_model_{}.pt'.format(model_type))\n        print('epoch [{}/{}], loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T02:51:38.744423Z","iopub.execute_input":"2021-05-25T02:51:38.744817Z","iopub.status.idle":"2021-05-25T03:33:15.560709Z","shell.execute_reply.started":"2021-05-25T02:51:38.744773Z","shell.execute_reply":"2021-05-25T03:33:15.558747Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"epoch [1/1000], loss:0.0367\nepoch [2/1000], loss:0.0272\nepoch [3/1000], loss:0.0280\nepoch [4/1000], loss:0.0164\nepoch [5/1000], loss:0.0179\nepoch [6/1000], loss:0.0162\nepoch [7/1000], loss:0.0125\nepoch [8/1000], loss:0.0136\nepoch [9/1000], loss:0.0118\nepoch [10/1000], loss:0.0128\nepoch [11/1000], loss:0.0120\nepoch [12/1000], loss:0.0119\nepoch [13/1000], loss:0.0106\nepoch [14/1000], loss:0.0103\nepoch [15/1000], loss:0.0105\nepoch [16/1000], loss:0.0107\nepoch [17/1000], loss:0.0095\nepoch [18/1000], loss:0.0108\nepoch [19/1000], loss:0.0105\nepoch [20/1000], loss:0.0090\nepoch [21/1000], loss:0.0104\nepoch [22/1000], loss:0.0104\nepoch [23/1000], loss:0.0101\nepoch [24/1000], loss:0.0091\nepoch [25/1000], loss:0.0083\nepoch [26/1000], loss:0.0086\nepoch [27/1000], loss:0.0085\nepoch [28/1000], loss:0.0086\nepoch [29/1000], loss:0.0084\nepoch [30/1000], loss:0.0064\nepoch [31/1000], loss:0.0072\nepoch [32/1000], loss:0.0070\nepoch [33/1000], loss:0.0071\nepoch [34/1000], loss:0.0077\nepoch [35/1000], loss:0.0073\nepoch [36/1000], loss:0.0069\nepoch [37/1000], loss:0.0077\nepoch [38/1000], loss:0.0064\nepoch [39/1000], loss:0.0069\nepoch [40/1000], loss:0.0065\nepoch [41/1000], loss:0.0057\nepoch [42/1000], loss:0.0057\nepoch [43/1000], loss:0.0061\nepoch [44/1000], loss:0.0066\nepoch [45/1000], loss:0.0061\nepoch [46/1000], loss:0.0065\nepoch [47/1000], loss:0.0098\nepoch [48/1000], loss:0.0051\nepoch [49/1000], loss:0.0055\nepoch [50/1000], loss:0.0054\nepoch [51/1000], loss:0.0045\nepoch [52/1000], loss:0.0053\nepoch [53/1000], loss:0.0062\nepoch [54/1000], loss:0.0046\nepoch [55/1000], loss:0.0058\nepoch [56/1000], loss:0.0057\nepoch [57/1000], loss:0.0056\nepoch [58/1000], loss:0.0057\nepoch [59/1000], loss:0.0048\nepoch [60/1000], loss:0.0058\nepoch [61/1000], loss:0.0057\nepoch [62/1000], loss:0.0059\nepoch [63/1000], loss:0.0045\nepoch [64/1000], loss:0.0049\nepoch [65/1000], loss:0.0053\nepoch [66/1000], loss:0.0049\nepoch [67/1000], loss:0.0051\nepoch [68/1000], loss:0.0050\nepoch [69/1000], loss:0.0054\nepoch [70/1000], loss:0.0050\nepoch [71/1000], loss:0.0046\nepoch [72/1000], loss:0.0043\nepoch [73/1000], loss:0.0051\nepoch [74/1000], loss:0.0053\nepoch [75/1000], loss:0.0044\nepoch [76/1000], loss:0.0045\nepoch [77/1000], loss:0.0051\nepoch [78/1000], loss:0.0043\nepoch [79/1000], loss:0.0039\nepoch [80/1000], loss:0.0040\nepoch [81/1000], loss:0.0044\nepoch [82/1000], loss:0.0041\nepoch [83/1000], loss:0.0038\nepoch [84/1000], loss:0.0043\nepoch [85/1000], loss:0.0046\nepoch [86/1000], loss:0.0049\nepoch [87/1000], loss:0.0049\nepoch [88/1000], loss:0.0039\nepoch [89/1000], loss:0.0042\nepoch [90/1000], loss:0.0043\nepoch [91/1000], loss:0.0044\nepoch [92/1000], loss:0.0046\nepoch [93/1000], loss:0.0037\nepoch [94/1000], loss:0.0044\nepoch [95/1000], loss:0.0036\nepoch [96/1000], loss:0.0043\nepoch [97/1000], loss:0.0051\nepoch [98/1000], loss:0.0048\nepoch [99/1000], loss:0.0039\nepoch [100/1000], loss:0.0041\nepoch [101/1000], loss:0.0042\nepoch [102/1000], loss:0.0042\nepoch [103/1000], loss:0.0045\nepoch [104/1000], loss:0.0044\nepoch [105/1000], loss:0.0037\nepoch [106/1000], loss:0.0039\nepoch [107/1000], loss:0.0039\nepoch [108/1000], loss:0.0042\nepoch [109/1000], loss:0.0036\nepoch [110/1000], loss:0.0041\nepoch [111/1000], loss:0.0039\nepoch [112/1000], loss:0.0038\nepoch [113/1000], loss:0.0037\nepoch [114/1000], loss:0.0037\nepoch [115/1000], loss:0.0036\nepoch [116/1000], loss:0.0038\nepoch [117/1000], loss:0.0038\nepoch [118/1000], loss:0.0034\nepoch [119/1000], loss:0.0039\nepoch [120/1000], loss:0.0037\nepoch [121/1000], loss:0.0037\nepoch [122/1000], loss:0.0036\nepoch [123/1000], loss:0.0038\nepoch [124/1000], loss:0.0035\nepoch [125/1000], loss:0.0043\nepoch [126/1000], loss:0.0036\nepoch [127/1000], loss:0.0035\nepoch [128/1000], loss:0.0038\nepoch [129/1000], loss:0.0047\nepoch [130/1000], loss:0.0031\nepoch [131/1000], loss:0.0034\nepoch [132/1000], loss:0.0036\nepoch [133/1000], loss:0.0040\nepoch [134/1000], loss:0.0035\nepoch [135/1000], loss:0.0042\nepoch [136/1000], loss:0.0036\nepoch [137/1000], loss:0.0035\nepoch [138/1000], loss:0.0035\nepoch [139/1000], loss:0.0035\nepoch [140/1000], loss:0.0033\nepoch [141/1000], loss:0.0039\nepoch [142/1000], loss:0.0035\nepoch [143/1000], loss:0.0035\nepoch [144/1000], loss:0.0034\nepoch [145/1000], loss:0.0035\nepoch [146/1000], loss:0.0033\nepoch [147/1000], loss:0.0030\nepoch [148/1000], loss:0.0036\nepoch [149/1000], loss:0.0034\nepoch [150/1000], loss:0.0033\nepoch [151/1000], loss:0.0045\nepoch [152/1000], loss:0.0038\nepoch [153/1000], loss:0.0031\nepoch [154/1000], loss:0.0037\nepoch [155/1000], loss:0.0034\nepoch [156/1000], loss:0.0031\nepoch [157/1000], loss:0.0041\nepoch [158/1000], loss:0.0036\nepoch [159/1000], loss:0.0041\nepoch [160/1000], loss:0.0036\nepoch [161/1000], loss:0.0036\nepoch [162/1000], loss:0.0040\nepoch [163/1000], loss:0.0038\nepoch [164/1000], loss:0.0035\nepoch [165/1000], loss:0.0037\nepoch [166/1000], loss:0.0039\nepoch [167/1000], loss:0.0032\nepoch [168/1000], loss:0.0039\nepoch [169/1000], loss:0.0035\nepoch [170/1000], loss:0.0030\nepoch [171/1000], loss:0.0030\nepoch [172/1000], loss:0.0038\nepoch [173/1000], loss:0.0035\nepoch [174/1000], loss:0.0038\nepoch [175/1000], loss:0.0031\nepoch [176/1000], loss:0.0030\nepoch [177/1000], loss:0.0040\nepoch [178/1000], loss:0.0033\nepoch [179/1000], loss:0.0030\nepoch [180/1000], loss:0.0035\nepoch [181/1000], loss:0.0034\nepoch [182/1000], loss:0.0032\nepoch [183/1000], loss:0.0030\nepoch [184/1000], loss:0.0033\nepoch [185/1000], loss:0.0032\nepoch [186/1000], loss:0.0032\nepoch [187/1000], loss:0.0030\nepoch [188/1000], loss:0.0033\nepoch [189/1000], loss:0.0030\nepoch [190/1000], loss:0.0034\nepoch [191/1000], loss:0.0034\nepoch [192/1000], loss:0.0031\nepoch [193/1000], loss:0.0029\nepoch [194/1000], loss:0.0035\nepoch [195/1000], loss:0.0056\nepoch [196/1000], loss:0.0037\nepoch [197/1000], loss:0.0035\nepoch [198/1000], loss:0.0033\nepoch [199/1000], loss:0.0033\nepoch [200/1000], loss:0.0044\nepoch [201/1000], loss:0.0034\nepoch [202/1000], loss:0.0033\nepoch [203/1000], loss:0.0042\nepoch [204/1000], loss:0.0035\nepoch [205/1000], loss:0.0030\nepoch [206/1000], loss:0.0029\nepoch [207/1000], loss:0.0037\nepoch [208/1000], loss:0.0032\nepoch [209/1000], loss:0.0032\nepoch [210/1000], loss:0.0033\nepoch [211/1000], loss:0.0031\nepoch [212/1000], loss:0.0038\nepoch [213/1000], loss:0.0034\nepoch [214/1000], loss:0.0034\nepoch [215/1000], loss:0.0031\nepoch [216/1000], loss:0.0033\nepoch [217/1000], loss:0.0033\nepoch [218/1000], loss:0.0029\nepoch [219/1000], loss:0.0031\nepoch [220/1000], loss:0.0034\nepoch [221/1000], loss:0.0027\nepoch [222/1000], loss:0.0032\nepoch [223/1000], loss:0.0036\nepoch [224/1000], loss:0.0034\nepoch [225/1000], loss:0.0033\nepoch [226/1000], loss:0.0031\nepoch [227/1000], loss:0.0032\nepoch [228/1000], loss:0.0038\nepoch [229/1000], loss:0.0030\nepoch [230/1000], loss:0.0033\nepoch [231/1000], loss:0.0035\nepoch [232/1000], loss:0.0029\nepoch [233/1000], loss:0.0031\nepoch [234/1000], loss:0.0032\nepoch [235/1000], loss:0.0030\nepoch [236/1000], loss:0.0028\nepoch [237/1000], loss:0.0036\nepoch [238/1000], loss:0.0034\nepoch [239/1000], loss:0.0029\nepoch [240/1000], loss:0.0038\nepoch [241/1000], loss:0.0033\nepoch [242/1000], loss:0.0031\nepoch [243/1000], loss:0.0038\nepoch [244/1000], loss:0.0033\nepoch [245/1000], loss:0.0033\nepoch [246/1000], loss:0.0028\nepoch [247/1000], loss:0.0033\nepoch [248/1000], loss:0.0037\nepoch [249/1000], loss:0.0031\nepoch [250/1000], loss:0.0034\nepoch [251/1000], loss:0.0030\nepoch [252/1000], loss:0.0031\nepoch [253/1000], loss:0.0032\nepoch [254/1000], loss:0.0031\nepoch [255/1000], loss:0.0029\nepoch [256/1000], loss:0.0029\nepoch [257/1000], loss:0.0034\nepoch [258/1000], loss:0.0033\nepoch [259/1000], loss:0.0032\nepoch [260/1000], loss:0.0034\nepoch [261/1000], loss:0.0032\nepoch [262/1000], loss:0.0033\nepoch [263/1000], loss:0.0038\nepoch [264/1000], loss:0.0030\nepoch [265/1000], loss:0.0034\nepoch [266/1000], loss:0.0032\nepoch [267/1000], loss:0.0029\nepoch [268/1000], loss:0.0031\nepoch [269/1000], loss:0.0034\nepoch [270/1000], loss:0.0029\nepoch [271/1000], loss:0.0040\nepoch [272/1000], loss:0.0036\nepoch [273/1000], loss:0.0028\nepoch [274/1000], loss:0.0032\nepoch [275/1000], loss:0.0033\nepoch [276/1000], loss:0.0033\nepoch [277/1000], loss:0.0038\nepoch [278/1000], loss:0.0031\nepoch [279/1000], loss:0.0035\nepoch [280/1000], loss:0.0029\nepoch [281/1000], loss:0.0035\nepoch [282/1000], loss:0.0032\nepoch [283/1000], loss:0.0033\nepoch [284/1000], loss:0.0033\nepoch [285/1000], loss:0.0032\nepoch [286/1000], loss:0.0034\nepoch [287/1000], loss:0.0033\nepoch [288/1000], loss:0.0032\nepoch [289/1000], loss:0.0029\nepoch [290/1000], loss:0.0030\nepoch [291/1000], loss:0.0031\nepoch [292/1000], loss:0.0030\nepoch [293/1000], loss:0.0031\nepoch [294/1000], loss:0.0032\nepoch [295/1000], loss:0.0032\nepoch [296/1000], loss:0.0037\nepoch [297/1000], loss:0.0031\nepoch [298/1000], loss:0.0030\nepoch [299/1000], loss:0.0032\nepoch [300/1000], loss:0.0031\nepoch [301/1000], loss:0.0038\nepoch [302/1000], loss:0.0035\nepoch [303/1000], loss:0.0032\nepoch [304/1000], loss:0.0030\nepoch [305/1000], loss:0.0032\nepoch [306/1000], loss:0.0030\nepoch [307/1000], loss:0.0032\nepoch [308/1000], loss:0.0034\nepoch [309/1000], loss:0.0030\nepoch [310/1000], loss:0.0034\nepoch [311/1000], loss:0.0031\nepoch [312/1000], loss:0.0032\nepoch [313/1000], loss:0.0031\nepoch [314/1000], loss:0.0033\nepoch [315/1000], loss:0.0031\nepoch [316/1000], loss:0.0030\nepoch [317/1000], loss:0.0035\nepoch [318/1000], loss:0.0030\nepoch [319/1000], loss:0.0034\nepoch [320/1000], loss:0.0030\nepoch [321/1000], loss:0.0032\nepoch [322/1000], loss:0.0034\nepoch [323/1000], loss:0.0030\nepoch [324/1000], loss:0.0029\nepoch [325/1000], loss:0.0030\nepoch [326/1000], loss:0.0035\nepoch [327/1000], loss:0.0026\nepoch [328/1000], loss:0.0027\nepoch [329/1000], loss:0.0036\nepoch [330/1000], loss:0.0030\nepoch [331/1000], loss:0.0034\nepoch [332/1000], loss:0.0032\nepoch [333/1000], loss:0.0032\nepoch [334/1000], loss:0.0028\nepoch [335/1000], loss:0.0034\nepoch [336/1000], loss:0.0034\nepoch [337/1000], loss:0.0035\nepoch [338/1000], loss:0.0033\nepoch [339/1000], loss:0.0034\nepoch [340/1000], loss:0.0032\nepoch [341/1000], loss:0.0030\nepoch [342/1000], loss:0.0035\nepoch [343/1000], loss:0.0032\nepoch [344/1000], loss:0.0031\nepoch [345/1000], loss:0.0031\nepoch [346/1000], loss:0.0041\nepoch [347/1000], loss:0.0030\nepoch [348/1000], loss:0.0031\nepoch [349/1000], loss:0.0033\nepoch [350/1000], loss:0.0033\nepoch [351/1000], loss:0.0032\nepoch [352/1000], loss:0.0027\nepoch [353/1000], loss:0.0033\nepoch [354/1000], loss:0.0036\nepoch [355/1000], loss:0.0029\nepoch [356/1000], loss:0.0033\nepoch [357/1000], loss:0.0031\nepoch [358/1000], loss:0.0044\nepoch [359/1000], loss:0.0041\nepoch [360/1000], loss:0.0032\nepoch [361/1000], loss:0.0031\nepoch [362/1000], loss:0.0029\nepoch [363/1000], loss:0.0029\nepoch [364/1000], loss:0.0029\nepoch [365/1000], loss:0.0032\nepoch [366/1000], loss:0.0033\nepoch [367/1000], loss:0.0035\nepoch [368/1000], loss:0.0030\nepoch [369/1000], loss:0.0034\nepoch [370/1000], loss:0.0028\nepoch [371/1000], loss:0.0030\nepoch [372/1000], loss:0.0031\nepoch [373/1000], loss:0.0027\nepoch [374/1000], loss:0.0031\nepoch [375/1000], loss:0.0032\nepoch [376/1000], loss:0.0029\nepoch [377/1000], loss:0.0036\nepoch [378/1000], loss:0.0038\nepoch [379/1000], loss:0.0034\nepoch [380/1000], loss:0.0033\nepoch [381/1000], loss:0.0029\nepoch [382/1000], loss:0.0031\nepoch [383/1000], loss:0.0033\nepoch [384/1000], loss:0.0034\nepoch [385/1000], loss:0.0035\nepoch [386/1000], loss:0.0033\nepoch [387/1000], loss:0.0034\nepoch [388/1000], loss:0.0032\nepoch [389/1000], loss:0.0037\nepoch [390/1000], loss:0.0028\nepoch [391/1000], loss:0.0051\nepoch [392/1000], loss:0.0031\nepoch [393/1000], loss:0.0032\nepoch [394/1000], loss:0.0036\nepoch [395/1000], loss:0.0034\nepoch [396/1000], loss:0.0032\nepoch [397/1000], loss:0.0038\nepoch [398/1000], loss:0.0033\nepoch [399/1000], loss:0.0031\nepoch [400/1000], loss:0.0030\nepoch [401/1000], loss:0.0031\nepoch [402/1000], loss:0.0029\nepoch [403/1000], loss:0.0033\nepoch [404/1000], loss:0.0034\nepoch [405/1000], loss:0.0032\nepoch [406/1000], loss:0.0030\nepoch [407/1000], loss:0.0032\nepoch [408/1000], loss:0.0034\nepoch [409/1000], loss:0.0032\nepoch [410/1000], loss:0.0029\nepoch [411/1000], loss:0.0030\nepoch [412/1000], loss:0.0031\nepoch [413/1000], loss:0.0032\nepoch [414/1000], loss:0.0030\nepoch [415/1000], loss:0.0027\nepoch [416/1000], loss:0.0039\nepoch [417/1000], loss:0.0031\nepoch [418/1000], loss:0.0038\nepoch [419/1000], loss:0.0031\nepoch [420/1000], loss:0.0030\nepoch [421/1000], loss:0.0028\nepoch [422/1000], loss:0.0033\nepoch [423/1000], loss:0.0036\nepoch [424/1000], loss:0.0033\nepoch [425/1000], loss:0.0034\nepoch [426/1000], loss:0.0036\nepoch [427/1000], loss:0.0027\nepoch [428/1000], loss:0.0037\nepoch [429/1000], loss:0.0033\nepoch [430/1000], loss:0.0027\nepoch [431/1000], loss:0.0034\nepoch [432/1000], loss:0.0035\nepoch [433/1000], loss:0.0028\nepoch [434/1000], loss:0.0031\nepoch [435/1000], loss:0.0031\nepoch [436/1000], loss:0.0033\nepoch [437/1000], loss:0.0029\nepoch [438/1000], loss:0.0030\nepoch [439/1000], loss:0.0029\nepoch [440/1000], loss:0.0027\nepoch [441/1000], loss:0.0035\nepoch [442/1000], loss:0.0037\nepoch [443/1000], loss:0.0032\nepoch [444/1000], loss:0.0032\nepoch [445/1000], loss:0.0030\nepoch [446/1000], loss:0.0031\nepoch [447/1000], loss:0.0028\nepoch [448/1000], loss:0.0033\nepoch [449/1000], loss:0.0031\nepoch [450/1000], loss:0.0029\nepoch [451/1000], loss:0.0036\nepoch [452/1000], loss:0.0034\nepoch [453/1000], loss:0.0032\nepoch [454/1000], loss:0.0038\nepoch [455/1000], loss:0.0028\nepoch [456/1000], loss:0.0029\nepoch [457/1000], loss:0.0030\nepoch [458/1000], loss:0.0031\nepoch [459/1000], loss:0.0033\nepoch [460/1000], loss:0.0031\nepoch [461/1000], loss:0.0030\nepoch [462/1000], loss:0.0030\nepoch [463/1000], loss:0.0030\nepoch [464/1000], loss:0.0033\nepoch [465/1000], loss:0.0029\nepoch [466/1000], loss:0.0040\nepoch [467/1000], loss:0.0029\nepoch [468/1000], loss:0.0036\nepoch [469/1000], loss:0.0028\nepoch [470/1000], loss:0.0032\nepoch [471/1000], loss:0.0029\nepoch [472/1000], loss:0.0036\nepoch [473/1000], loss:0.0035\nepoch [474/1000], loss:0.0033\nepoch [475/1000], loss:0.0028\nepoch [476/1000], loss:0.0032\nepoch [477/1000], loss:0.0034\nepoch [478/1000], loss:0.0028\nepoch [479/1000], loss:0.0036\nepoch [480/1000], loss:0.0032\nepoch [481/1000], loss:0.0030\nepoch [482/1000], loss:0.0030\nepoch [483/1000], loss:0.0028\nepoch [484/1000], loss:0.0031\nepoch [485/1000], loss:0.0036\nepoch [486/1000], loss:0.0033\nepoch [487/1000], loss:0.0033\nepoch [488/1000], loss:0.0034\nepoch [489/1000], loss:0.0028\nepoch [490/1000], loss:0.0030\nepoch [491/1000], loss:0.0032\nepoch [492/1000], loss:0.0032\nepoch [493/1000], loss:0.0028\nepoch [494/1000], loss:0.0031\nepoch [495/1000], loss:0.0036\nepoch [496/1000], loss:0.0032\nepoch [497/1000], loss:0.0028\nepoch [498/1000], loss:0.0034\nepoch [499/1000], loss:0.0036\nepoch [500/1000], loss:0.0031\nepoch [501/1000], loss:0.0037\nepoch [502/1000], loss:0.0031\nepoch [503/1000], loss:0.0031\nepoch [504/1000], loss:0.0029\nepoch [505/1000], loss:0.0035\nepoch [506/1000], loss:0.0028\nepoch [507/1000], loss:0.0035\nepoch [508/1000], loss:0.0031\nepoch [509/1000], loss:0.0031\nepoch [510/1000], loss:0.0030\nepoch [511/1000], loss:0.0028\nepoch [512/1000], loss:0.0037\nepoch [513/1000], loss:0.0028\nepoch [514/1000], loss:0.0032\nepoch [515/1000], loss:0.0033\nepoch [516/1000], loss:0.0031\nepoch [517/1000], loss:0.0032\nepoch [518/1000], loss:0.0032\nepoch [519/1000], loss:0.0031\nepoch [520/1000], loss:0.0033\nepoch [521/1000], loss:0.0034\nepoch [522/1000], loss:0.0030\nepoch [523/1000], loss:0.0028\nepoch [524/1000], loss:0.0033\nepoch [525/1000], loss:0.0033\nepoch [526/1000], loss:0.0032\nepoch [527/1000], loss:0.0030\nepoch [528/1000], loss:0.0038\nepoch [529/1000], loss:0.0027\nepoch [530/1000], loss:0.0031\nepoch [531/1000], loss:0.0033\nepoch [532/1000], loss:0.0027\nepoch [533/1000], loss:0.0026\nepoch [534/1000], loss:0.0032\nepoch [535/1000], loss:0.0031\nepoch [536/1000], loss:0.0034\nepoch [537/1000], loss:0.0035\nepoch [538/1000], loss:0.0037\nepoch [539/1000], loss:0.0033\nepoch [540/1000], loss:0.0030\nepoch [541/1000], loss:0.0031\nepoch [542/1000], loss:0.0035\nepoch [543/1000], loss:0.0030\nepoch [544/1000], loss:0.0030\nepoch [545/1000], loss:0.0031\nepoch [546/1000], loss:0.0031\nepoch [547/1000], loss:0.0031\nepoch [548/1000], loss:0.0029\nepoch [549/1000], loss:0.0035\nepoch [550/1000], loss:0.0033\nepoch [551/1000], loss:0.0031\nepoch [552/1000], loss:0.0031\nepoch [553/1000], loss:0.0031\nepoch [554/1000], loss:0.0030\nepoch [555/1000], loss:0.0029\nepoch [556/1000], loss:0.0027\nepoch [557/1000], loss:0.0029\nepoch [558/1000], loss:0.0031\nepoch [559/1000], loss:0.0031\nepoch [560/1000], loss:0.0034\nepoch [561/1000], loss:0.0032\nepoch [562/1000], loss:0.0033\nepoch [563/1000], loss:0.0038\nepoch [564/1000], loss:0.0033\nepoch [565/1000], loss:0.0031\nepoch [566/1000], loss:0.0034\nepoch [567/1000], loss:0.0032\nepoch [568/1000], loss:0.0033\nepoch [569/1000], loss:0.0028\nepoch [570/1000], loss:0.0029\nepoch [571/1000], loss:0.0031\nepoch [572/1000], loss:0.0033\nepoch [573/1000], loss:0.0036\nepoch [574/1000], loss:0.0036\nepoch [575/1000], loss:0.0032\nepoch [576/1000], loss:0.0031\nepoch [577/1000], loss:0.0034\nepoch [578/1000], loss:0.0037\nepoch [579/1000], loss:0.0029\nepoch [580/1000], loss:0.0035\nepoch [581/1000], loss:0.0038\nepoch [582/1000], loss:0.0030\nepoch [583/1000], loss:0.0034\nepoch [584/1000], loss:0.0028\nepoch [585/1000], loss:0.0032\nepoch [586/1000], loss:0.0028\nepoch [587/1000], loss:0.0032\nepoch [588/1000], loss:0.0031\nepoch [589/1000], loss:0.0030\nepoch [590/1000], loss:0.0028\nepoch [591/1000], loss:0.0037\nepoch [592/1000], loss:0.0027\nepoch [593/1000], loss:0.0033\nepoch [594/1000], loss:0.0029\nepoch [595/1000], loss:0.0039\nepoch [596/1000], loss:0.0035\nepoch [597/1000], loss:0.0032\nepoch [598/1000], loss:0.0033\nepoch [599/1000], loss:0.0032\nepoch [600/1000], loss:0.0031\nepoch [601/1000], loss:0.0031\nepoch [602/1000], loss:0.0032\nepoch [603/1000], loss:0.0033\nepoch [604/1000], loss:0.0029\nepoch [605/1000], loss:0.0034\nepoch [606/1000], loss:0.0035\nepoch [607/1000], loss:0.0033\nepoch [608/1000], loss:0.0029\nepoch [609/1000], loss:0.0032\nepoch [610/1000], loss:0.0029\nepoch [611/1000], loss:0.0032\nepoch [612/1000], loss:0.0035\nepoch [613/1000], loss:0.0025\nepoch [614/1000], loss:0.0033\nepoch [615/1000], loss:0.0036\nepoch [616/1000], loss:0.0030\nepoch [617/1000], loss:0.0028\nepoch [618/1000], loss:0.0037\nepoch [619/1000], loss:0.0027\nepoch [620/1000], loss:0.0034\nepoch [621/1000], loss:0.0036\nepoch [622/1000], loss:0.0032\nepoch [623/1000], loss:0.0030\nepoch [624/1000], loss:0.0033\nepoch [625/1000], loss:0.0028\nepoch [626/1000], loss:0.0029\nepoch [627/1000], loss:0.0030\nepoch [628/1000], loss:0.0026\nepoch [629/1000], loss:0.0027\nepoch [630/1000], loss:0.0033\nepoch [631/1000], loss:0.0029\nepoch [632/1000], loss:0.0030\nepoch [633/1000], loss:0.0030\nepoch [634/1000], loss:0.0032\nepoch [635/1000], loss:0.0028\nepoch [636/1000], loss:0.0028\nepoch [637/1000], loss:0.0030\nepoch [638/1000], loss:0.0036\nepoch [639/1000], loss:0.0034\nepoch [640/1000], loss:0.0031\nepoch [641/1000], loss:0.0028\nepoch [642/1000], loss:0.0035\nepoch [643/1000], loss:0.0038\nepoch [644/1000], loss:0.0026\nepoch [645/1000], loss:0.0030\nepoch [646/1000], loss:0.0032\nepoch [647/1000], loss:0.0032\nepoch [648/1000], loss:0.0034\nepoch [649/1000], loss:0.0034\nepoch [650/1000], loss:0.0030\nepoch [651/1000], loss:0.0027\nepoch [652/1000], loss:0.0032\nepoch [653/1000], loss:0.0033\nepoch [654/1000], loss:0.0027\nepoch [655/1000], loss:0.0032\nepoch [656/1000], loss:0.0034\nepoch [657/1000], loss:0.0032\nepoch [658/1000], loss:0.0034\nepoch [659/1000], loss:0.0032\nepoch [660/1000], loss:0.0035\nepoch [661/1000], loss:0.0032\nepoch [662/1000], loss:0.0032\nepoch [663/1000], loss:0.0032\nepoch [664/1000], loss:0.0029\nepoch [665/1000], loss:0.0029\nepoch [666/1000], loss:0.0030\nepoch [667/1000], loss:0.0037\nepoch [668/1000], loss:0.0029\nepoch [669/1000], loss:0.0028\nepoch [670/1000], loss:0.0030\nepoch [671/1000], loss:0.0030\nepoch [672/1000], loss:0.0027\nepoch [673/1000], loss:0.0030\nepoch [674/1000], loss:0.0031\nepoch [675/1000], loss:0.0032\nepoch [676/1000], loss:0.0031\nepoch [677/1000], loss:0.0030\nepoch [678/1000], loss:0.0030\nepoch [679/1000], loss:0.0030\nepoch [680/1000], loss:0.0033\nepoch [681/1000], loss:0.0030\nepoch [682/1000], loss:0.0029\nepoch [683/1000], loss:0.0028\nepoch [684/1000], loss:0.0027\nepoch [685/1000], loss:0.0025\nepoch [686/1000], loss:0.0029\nepoch [687/1000], loss:0.0031\nepoch [688/1000], loss:0.0034\nepoch [689/1000], loss:0.0036\nepoch [690/1000], loss:0.0026\nepoch [691/1000], loss:0.0029\nepoch [692/1000], loss:0.0033\nepoch [693/1000], loss:0.0028\nepoch [694/1000], loss:0.0030\nepoch [695/1000], loss:0.0028\nepoch [696/1000], loss:0.0026\nepoch [697/1000], loss:0.0029\nepoch [698/1000], loss:0.0030\nepoch [699/1000], loss:0.0031\nepoch [700/1000], loss:0.0032\nepoch [701/1000], loss:0.0034\nepoch [702/1000], loss:0.0037\nepoch [703/1000], loss:0.0031\nepoch [704/1000], loss:0.0026\nepoch [705/1000], loss:0.0031\nepoch [706/1000], loss:0.0033\nepoch [707/1000], loss:0.0031\nepoch [708/1000], loss:0.0028\nepoch [709/1000], loss:0.0025\nepoch [710/1000], loss:0.0034\nepoch [711/1000], loss:0.0031\nepoch [712/1000], loss:0.0030\nepoch [713/1000], loss:0.0038\nepoch [714/1000], loss:0.0031\nepoch [715/1000], loss:0.0028\nepoch [716/1000], loss:0.0029\nepoch [717/1000], loss:0.0030\nepoch [718/1000], loss:0.0033\nepoch [719/1000], loss:0.0032\nepoch [720/1000], loss:0.0032\nepoch [721/1000], loss:0.0033\nepoch [722/1000], loss:0.0029\nepoch [723/1000], loss:0.0029\nepoch [724/1000], loss:0.0030\nepoch [725/1000], loss:0.0032\nepoch [726/1000], loss:0.0036\nepoch [727/1000], loss:0.0033\nepoch [728/1000], loss:0.0027\nepoch [729/1000], loss:0.0028\nepoch [730/1000], loss:0.0032\nepoch [731/1000], loss:0.0031\nepoch [732/1000], loss:0.0031\nepoch [733/1000], loss:0.0032\nepoch [734/1000], loss:0.0030\nepoch [735/1000], loss:0.0030\nepoch [736/1000], loss:0.0032\nepoch [737/1000], loss:0.0030\nepoch [738/1000], loss:0.0033\nepoch [739/1000], loss:0.0031\nepoch [740/1000], loss:0.0033\nepoch [741/1000], loss:0.0031\nepoch [742/1000], loss:0.0033\nepoch [743/1000], loss:0.0032\nepoch [744/1000], loss:0.0033\nepoch [745/1000], loss:0.0030\nepoch [746/1000], loss:0.0029\nepoch [747/1000], loss:0.0033\nepoch [748/1000], loss:0.0028\nepoch [749/1000], loss:0.0032\nepoch [750/1000], loss:0.0034\nepoch [751/1000], loss:0.0028\nepoch [752/1000], loss:0.0034\nepoch [753/1000], loss:0.0028\nepoch [754/1000], loss:0.0029\nepoch [755/1000], loss:0.0029\nepoch [756/1000], loss:0.0031\nepoch [757/1000], loss:0.0031\nepoch [758/1000], loss:0.0029\nepoch [759/1000], loss:0.0032\nepoch [760/1000], loss:0.0032\nepoch [761/1000], loss:0.0031\nepoch [762/1000], loss:0.0036\nepoch [763/1000], loss:0.0029\nepoch [764/1000], loss:0.0033\nepoch [765/1000], loss:0.0027\nepoch [766/1000], loss:0.0032\nepoch [767/1000], loss:0.0033\nepoch [768/1000], loss:0.0030\nepoch [769/1000], loss:0.0034\nepoch [770/1000], loss:0.0030\nepoch [771/1000], loss:0.0031\nepoch [772/1000], loss:0.0027\nepoch [773/1000], loss:0.0030\nepoch [774/1000], loss:0.0028\nepoch [775/1000], loss:0.0034\nepoch [776/1000], loss:0.0026\nepoch [777/1000], loss:0.0031\nepoch [778/1000], loss:0.0031\nepoch [779/1000], loss:0.0024\nepoch [780/1000], loss:0.0031\nepoch [781/1000], loss:0.0030\nepoch [782/1000], loss:0.0027\nepoch [783/1000], loss:0.0030\nepoch [784/1000], loss:0.0029\nepoch [785/1000], loss:0.0035\nepoch [786/1000], loss:0.0028\nepoch [787/1000], loss:0.0026\nepoch [788/1000], loss:0.0034\nepoch [789/1000], loss:0.0030\nepoch [790/1000], loss:0.0029\nepoch [791/1000], loss:0.0029\nepoch [792/1000], loss:0.0032\nepoch [793/1000], loss:0.0032\nepoch [794/1000], loss:0.0035\nepoch [795/1000], loss:0.0030\nepoch [796/1000], loss:0.0037\nepoch [797/1000], loss:0.0037\nepoch [798/1000], loss:0.0027\nepoch [799/1000], loss:0.0030\nepoch [800/1000], loss:0.0034\nepoch [801/1000], loss:0.0031\nepoch [802/1000], loss:0.0031\nepoch [803/1000], loss:0.0027\nepoch [804/1000], loss:0.0031\nepoch [805/1000], loss:0.0031\nepoch [806/1000], loss:0.0029\nepoch [807/1000], loss:0.0029\nepoch [808/1000], loss:0.0029\nepoch [809/1000], loss:0.0029\nepoch [810/1000], loss:0.0032\nepoch [811/1000], loss:0.0031\nepoch [812/1000], loss:0.0028\nepoch [813/1000], loss:0.0031\nepoch [814/1000], loss:0.0028\nepoch [815/1000], loss:0.0032\nepoch [816/1000], loss:0.0028\nepoch [817/1000], loss:0.0031\nepoch [818/1000], loss:0.0032\nepoch [819/1000], loss:0.0030\nepoch [820/1000], loss:0.0032\nepoch [821/1000], loss:0.0034\nepoch [822/1000], loss:0.0031\nepoch [823/1000], loss:0.0031\nepoch [824/1000], loss:0.0032\nepoch [825/1000], loss:0.0027\nepoch [826/1000], loss:0.0030\nepoch [827/1000], loss:0.0034\nepoch [828/1000], loss:0.0034\nepoch [829/1000], loss:0.0032\nepoch [830/1000], loss:0.0031\nepoch [831/1000], loss:0.0029\nepoch [832/1000], loss:0.0030\nepoch [833/1000], loss:0.0031\nepoch [834/1000], loss:0.0031\nepoch [835/1000], loss:0.0030\nepoch [836/1000], loss:0.0030\nepoch [837/1000], loss:0.0029\nepoch [838/1000], loss:0.0030\nepoch [839/1000], loss:0.0031\nepoch [840/1000], loss:0.0030\nepoch [841/1000], loss:0.0029\nepoch [842/1000], loss:0.0029\nepoch [843/1000], loss:0.0030\nepoch [844/1000], loss:0.0033\nepoch [845/1000], loss:0.0031\nepoch [846/1000], loss:0.0032\nepoch [847/1000], loss:0.0030\nepoch [848/1000], loss:0.0032\nepoch [849/1000], loss:0.0030\nepoch [850/1000], loss:0.0029\nepoch [851/1000], loss:0.0025\nepoch [852/1000], loss:0.0037\nepoch [853/1000], loss:0.0035\nepoch [854/1000], loss:0.0026\nepoch [855/1000], loss:0.0033\nepoch [856/1000], loss:0.0032\nepoch [857/1000], loss:0.0030\nepoch [858/1000], loss:0.0030\nepoch [859/1000], loss:0.0032\nepoch [860/1000], loss:0.0033\nepoch [861/1000], loss:0.0033\nepoch [862/1000], loss:0.0028\nepoch [863/1000], loss:0.0030\nepoch [864/1000], loss:0.0031\nepoch [865/1000], loss:0.0029\nepoch [866/1000], loss:0.0032\nepoch [867/1000], loss:0.0031\nepoch [868/1000], loss:0.0028\nepoch [869/1000], loss:0.0041\nepoch [870/1000], loss:0.0029\nepoch [871/1000], loss:0.0031\nepoch [872/1000], loss:0.0034\nepoch [873/1000], loss:0.0028\nepoch [874/1000], loss:0.0032\nepoch [875/1000], loss:0.0030\nepoch [876/1000], loss:0.0029\nepoch [877/1000], loss:0.0032\nepoch [878/1000], loss:0.0035\nepoch [879/1000], loss:0.0026\nepoch [880/1000], loss:0.0031\nepoch [881/1000], loss:0.0032\nepoch [882/1000], loss:0.0030\nepoch [883/1000], loss:0.0031\nepoch [884/1000], loss:0.0028\nepoch [885/1000], loss:0.0031\nepoch [886/1000], loss:0.0031\nepoch [887/1000], loss:0.0028\nepoch [888/1000], loss:0.0027\nepoch [889/1000], loss:0.0031\nepoch [890/1000], loss:0.0028\nepoch [891/1000], loss:0.0027\nepoch [892/1000], loss:0.0029\nepoch [893/1000], loss:0.0034\nepoch [894/1000], loss:0.0029\nepoch [895/1000], loss:0.0032\nepoch [896/1000], loss:0.0031\nepoch [897/1000], loss:0.0032\nepoch [898/1000], loss:0.0030\nepoch [899/1000], loss:0.0029\nepoch [900/1000], loss:0.0032\nepoch [901/1000], loss:0.0029\nepoch [902/1000], loss:0.0028\nepoch [903/1000], loss:0.0030\nepoch [904/1000], loss:0.0032\nepoch [905/1000], loss:0.0029\nepoch [906/1000], loss:0.0029\nepoch [907/1000], loss:0.0026\nepoch [908/1000], loss:0.0035\nepoch [909/1000], loss:0.0029\nepoch [910/1000], loss:0.0034\nepoch [911/1000], loss:0.0030\nepoch [912/1000], loss:0.0033\nepoch [913/1000], loss:0.0037\nepoch [914/1000], loss:0.0034\nepoch [915/1000], loss:0.0027\nepoch [916/1000], loss:0.0029\nepoch [917/1000], loss:0.0027\nepoch [918/1000], loss:0.0036\nepoch [919/1000], loss:0.0030\nepoch [920/1000], loss:0.0033\nepoch [921/1000], loss:0.0029\nepoch [922/1000], loss:0.0031\nepoch [923/1000], loss:0.0025\nepoch [924/1000], loss:0.0035\nepoch [925/1000], loss:0.0032\nepoch [926/1000], loss:0.0028\nepoch [927/1000], loss:0.0031\nepoch [928/1000], loss:0.0030\nepoch [929/1000], loss:0.0027\nepoch [930/1000], loss:0.0031\nepoch [931/1000], loss:0.0028\nepoch [932/1000], loss:0.0029\nepoch [933/1000], loss:0.0030\nepoch [934/1000], loss:0.0032\nepoch [935/1000], loss:0.0034\nepoch [936/1000], loss:0.0031\nepoch [937/1000], loss:0.0027\nepoch [938/1000], loss:0.0035\nepoch [939/1000], loss:0.0030\nepoch [940/1000], loss:0.0029\nepoch [941/1000], loss:0.0031\nepoch [942/1000], loss:0.0029\nepoch [943/1000], loss:0.0032\nepoch [944/1000], loss:0.0028\nepoch [945/1000], loss:0.0032\nepoch [946/1000], loss:0.0030\nepoch [947/1000], loss:0.0030\nepoch [948/1000], loss:0.0032\nepoch [949/1000], loss:0.0034\nepoch [950/1000], loss:0.0030\nepoch [951/1000], loss:0.0041\nepoch [952/1000], loss:0.0027\nepoch [953/1000], loss:0.0029\nepoch [954/1000], loss:0.0029\nepoch [955/1000], loss:0.0032\nepoch [956/1000], loss:0.0032\nepoch [957/1000], loss:0.0028\nepoch [958/1000], loss:0.0030\nepoch [959/1000], loss:0.0036\nepoch [960/1000], loss:0.0027\nepoch [961/1000], loss:0.0030\nepoch [962/1000], loss:0.0027\nepoch [963/1000], loss:0.0033\nepoch [964/1000], loss:0.0034\nepoch [965/1000], loss:0.0029\nepoch [966/1000], loss:0.0031\nepoch [967/1000], loss:0.0031\nepoch [968/1000], loss:0.0030\nepoch [969/1000], loss:0.0029\nepoch [970/1000], loss:0.0028\nepoch [971/1000], loss:0.0033\nepoch [972/1000], loss:0.0034\nepoch [973/1000], loss:0.0028\nepoch [974/1000], loss:0.0027\nepoch [975/1000], loss:0.0033\nepoch [976/1000], loss:0.0031\nepoch [977/1000], loss:0.0028\nepoch [978/1000], loss:0.0029\nepoch [979/1000], loss:0.0030\nepoch [980/1000], loss:0.0031\nepoch [981/1000], loss:0.0029\nepoch [982/1000], loss:0.0028\nepoch [983/1000], loss:0.0030\nepoch [984/1000], loss:0.0026\nepoch [985/1000], loss:0.0027\nepoch [986/1000], loss:0.0028\nepoch [987/1000], loss:0.0028\nepoch [988/1000], loss:0.0032\nepoch [989/1000], loss:0.0034\nepoch [990/1000], loss:0.0030\nepoch [991/1000], loss:0.0025\nepoch [992/1000], loss:0.0032\nepoch [993/1000], loss:0.0030\nepoch [994/1000], loss:0.0031\nepoch [995/1000], loss:0.0027\nepoch [996/1000], loss:0.0027\nepoch [997/1000], loss:0.0029\nepoch [998/1000], loss:0.0028\nepoch [999/1000], loss:0.0031\nepoch [1000/1000], loss:0.0027\n","output_type":"stream"}]},{"cell_type":"code","source":"if task == 'ae':\n    if model_type == 'fcn' or model_type == 'vae':\n        y = test.reshape(len(test), -1)\n    else:\n        y = test\n        \n    data = torch.tensor(y, dtype=torch.float)\n    test_dataset = TensorDataset(data)\n    test_sampler = SequentialSampler(test_dataset)\n    test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)\n    \n    model.eval()\n    reconstructed = list()\n    for i, data in enumerate(test_dataloader):\n        if model_type == 'cnn':\n            img = data[0].transpose(3, 1).cuda()\n        else:\n            img = data[0].cuda()\n        output = model(img)\n        if model_type == 'cnn':\n            output = output.transpose(3, 1)\n        elif model_type == 'vae':\n            output = output[0]\n        reconstructed.append(output.cpu().detach().numpy())\n    \n    reconstructed = np.concatenate(reconstructed, axis=0)\n    anomality = np.sqrt(np.sum(np.square(reconstructed - y).reshape(len(y), -1), axis=1))\n    y_pred = anomality\n    with open('prediction.csv', 'w') as f:\n        f.write('id, anomaly\\n')\n        for i in range(len(y_pred)):\n            f.write('{}, {}\\n'.format(i+1, y_pred[i]))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T03:35:36.643122Z","iopub.execute_input":"2021-05-25T03:35:36.643505Z","iopub.status.idle":"2021-05-25T03:35:37.431749Z","shell.execute_reply.started":"2021-05-25T03:35:36.643472Z","shell.execute_reply":"2021-05-25T03:35:37.430832Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}